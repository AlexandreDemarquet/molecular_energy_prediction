{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d953092f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n7student/.local/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "/home/n7student/.local/lib/python3.10/site-packages/torch_geometric/typing.py:72: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/n7student/.local/lib/python3.10/site-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from dataset.QM7XDataset import QM7XEmbedDataset\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1598bb",
   "metadata": {},
   "source": [
    "## Les donn√©es scattering et/ou contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb4b203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_X_y_train_test import get_X_y_train_test\n",
    "X_train, X_test, y_train, y_test = get_X_y_train_test(avec_coef_contrastive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b14a9b8",
   "metadata": {},
   "source": [
    "## Regression multi Lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c979556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.regression_multi_lin import RegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1965492f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([5931, 706]), y_train shape: torch.Size([5931, 1])\n",
      "X_test shape: torch.Size([660, 706]), y_test shape: torch.Size([660, 1])\n",
      "Epoch 1/20, Loss: 4268.9087\n",
      "Epoch 10/20, Loss: 4.3587\n",
      "Epoch 20/20, Loss: 2.6885\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch RMSE: 1.9219, R2: 0.9755, MAE: 0.7483\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Donn√©es X, y: numpy arrays\n",
    "# Exemple: X = np.array(...), y = np.array(...)\n",
    "\n",
    "# Param√®tres\n",
    "batch_size = 32\n",
    "lr = 1e-3\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "\n",
    "# Conversion en tenseurs PyTorch\n",
    "torch.manual_seed(42)\n",
    "X_train_t = torch.from_numpy(X_train).float()\n",
    "y_train_t = torch.from_numpy(y_train).float().unsqueeze(1)\n",
    "X_test_t = torch.from_numpy(X_test).float()\n",
    "y_test_t = torch.from_numpy(y_test).float().unsqueeze(1)\n",
    "\n",
    "print(f\"X_train shape: {X_train_t.shape}, y_train shape: {y_train_t.shape}\")\n",
    "print(f\"X_test shape: {X_test_t.shape}, y_test shape: {y_test_t.shape}\")\n",
    "# DataLoaders\n",
    "dataset_train = TensorDataset(X_train_t, y_train_t)\n",
    "dataset_test = TensorDataset(X_test_t, y_test_t)\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size)\n",
    "\n",
    "# Initialisation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "input_dim = X_train.shape[1]\n",
    "q = 300\n",
    "k = 3\n",
    "model = RegressionModel(input_dim, q, k).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# Entra√Ænement avec suivi de la loss\n",
    "history = []\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for xb, yb in loader_train:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(xb)\n",
    "        loss = criterion(preds, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses.append(loss.item())\n",
    "    avg_loss = np.mean(train_losses)\n",
    "    history.append(avg_loss)\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Plot de la loss d'entra√Ænement\n",
    "plt.figure()\n",
    "plt.plot(range(1, epochs+1), history)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss MSE')\n",
    "plt.title(\"Courbe de perte d'entra√Ænement\")\n",
    "plt.show()\n",
    "\n",
    "# √âvaluation sur test\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds_test = model(X_test_t.to(device)).cpu().squeeze().numpy()\n",
    "rmse = mean_squared_error(y_test, preds_test)**0.5\n",
    "mae = mean_absolute_error(y_test, preds_test)\n",
    "r2 = r2_score(y_test, preds_test)\n",
    "print(f\"PyTorch RMSE: {rmse:.4f}, R2: {r2:.4f}, MAE: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f9801",
   "metadata": {},
   "source": [
    "## Regressor Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01077298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 158801\n",
      "[LightGBM] [Info] Number of data points in the train set: 5931, number of used features: 667\n",
      "[LightGBM] [Info] Start training from score -77.923448\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016404 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 158801\n",
      "[LightGBM] [Info] Number of data points in the train set: 5931, number of used features: 667\n",
      "[LightGBM] [Info] Start training from score -77.923448\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.060670 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 158153\n",
      "[LightGBM] [Info] Number of data points in the train set: 4745, number of used features: 667\n",
      "[LightGBM] [Info] Start training from score -78.041196\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050183 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 158341\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.056179 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 158313\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.062010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Number of data points in the train set: 4745, number of used features: 667\n",
      "[LightGBM] [Info] Number of data points in the train set: 4745, number of used features: 667\n",
      "[LightGBM] [Info] Total Bins 158296\n",
      "[LightGBM] [Info] Start training from score -77.761363\n",
      "[LightGBM] [Info] Start training from score -77.939523\n",
      "[LightGBM] [Info] Total Bins 158278\n",
      "[LightGBM] [Info] Number of data points in the train set: 4744, number of used features: 667\n",
      "[LightGBM] [Info] Start training from score -77.979922\n",
      "[LightGBM] [Info] Number of data points in the train set: 4745, number of used features: 667\n",
      "[LightGBM] [Info] Start training from score -77.895247\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n7student/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/n7student/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/n7student/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/n7student/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/n7student/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking RMSE: 0.3614\n",
      "Stacking R¬≤:   0.9991\n",
      "Stacking MAE:  0.1736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n7student/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# 1) D√©finir les estimateurs sklearn-compatibles\n",
    "\n",
    "# XGBoost\n",
    "xgb_sk = XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse',\n",
    "    learning_rate=0.1,\n",
    "    max_depth=8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=10.0,\n",
    "    n_estimators=2,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "# LightGBM\n",
    "lgb_sk = LGBMRegressor(\n",
    "    objective='regression',\n",
    "    metric='rmse',\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=10.0,\n",
    "    n_estimators=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=2,\n",
    "    max_depth=20,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2) Entra√Æner chaque mod√®le sur vos donn√©es\n",
    "xgb_sk.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "lgb_sk.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# 3) Cr√©er et entra√Æner le stacking\n",
    "estimators = [\n",
    "    ('xgb', xgb_sk),\n",
    "    ('lgb', lgb_sk),\n",
    "    ('rf', rf)\n",
    "]\n",
    "stack = StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=Ridge(alpha=1.0),\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    passthrough=False\n",
    ")\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "# 4) √âvaluer\n",
    "y_pred = stack.predict(X_test)\n",
    "print(f\"Stacking RMSE: {mean_squared_error(y_test, y_pred)**0.5:.4f}\")\n",
    "print(f\"Stacking R¬≤:   {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Stacking MAE:  {mean_absolute_error(y_test, y_pred):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
